[["Map",1,2,9,10],"meta::meta",["Map",3,4,5,6,7,8],"astro-version","5.16.6","content-config-digest","ebd1d98c719c9986","astro-config-digest","{\"root\":{},\"srcDir\":{},\"publicDir\":{},\"outDir\":{},\"cacheDir\":{},\"site\":\"https://divkix.me\",\"compressHTML\":true,\"base\":\"/\",\"trailingSlash\":\"ignore\",\"output\":\"static\",\"scopedStyleStrategy\":\"attribute\",\"build\":{\"format\":\"directory\",\"client\":{},\"server\":{},\"assets\":\"_astro\",\"serverEntry\":\"entry.mjs\",\"redirects\":true,\"inlineStylesheets\":\"auto\",\"concurrency\":1},\"server\":{\"open\":false,\"host\":false,\"port\":4321,\"streaming\":true,\"allowedHosts\":[]},\"redirects\":{},\"prefetch\":{\"prefetchAll\":true},\"image\":{\"endpoint\":{\"route\":\"/_image\"},\"service\":{\"entrypoint\":\"astro/assets/services/sharp\",\"config\":{}},\"domains\":[],\"remotePatterns\":[],\"responsiveStyles\":false},\"devToolbar\":{\"enabled\":true},\"markdown\":{\"syntaxHighlight\":{\"type\":\"shiki\",\"excludeLangs\":[\"math\"]},\"shikiConfig\":{\"langs\":[],\"langAlias\":{},\"theme\":\"github-dark-dimmed\",\"themes\":{},\"wrap\":true,\"transformers\":[]},\"remarkPlugins\":[null],\"rehypePlugins\":[],\"remarkRehype\":{},\"gfm\":true,\"smartypants\":true},\"security\":{\"checkOrigin\":true,\"allowedDomains\":[]},\"env\":{\"schema\":{},\"validateSecrets\":false},\"experimental\":{\"clientPrerender\":false,\"contentIntellisense\":false,\"headingIdCompat\":false,\"preserveScriptOrder\":false,\"liveContentCollections\":false,\"csp\":false,\"staticImportMetaEnv\":false,\"chromeDevtoolsWorkspace\":false,\"failOnPrerenderConflict\":false,\"svgo\":false},\"legacy\":{\"collections\":false}}","blog",["Map",11,12,57,58,101,102,141,142,199,200,252,253],"ai-coding-tools-compared-2025",{"id":11,"data":13,"body":53,"filePath":54,"digest":55,"legacyId":56,"deferredRender":31},{"title":14,"date":15,"dateModified":16,"excerpt":17,"tags":18,"published":31,"author":32,"tldr":33,"keyTakeaways":34,"faq":40},"Claude Code vs Cursor vs Copilot (2025): Best AI Coding Tools Compared","2025-11-24","2025-12-24","I've spent $50+/month on AI coding tools for a year. Here's what actually works, what's overhyped, and when to use each tool (including free local LLMs).",[19,20,21,22,23,24,25,26,27,28,29,30],"AI","Claude Code","Cursor","GitHub Copilot","LM Studio","Coding Tools","Developer Experience","AI Assistants","Productivity","2025","Best AI Coding Assistant","2026",true,"Divanshu Chauhan","Different AI coding tools excel at different tasks - Claude Code for complex refactors, Cursor for exploration, Copilot for autocomplete, and LM Studio for privacy. Using all three strategically beats trying to force one tool for everything.",[35,36,37,38,39],"Claude Code dominates complex multi-file refactors and terminal-based workflows with MCP integrations","Cursor's chat-in-editor beats everything for exploratory coding and codebase questions","GitHub Copilot still has the best autocomplete flow - tab-tab-tab beats typing for boilerplate","Local LLMs (LM Studio) are essential for sensitive code and offline work despite being slower","Cost breakdown: You'll pay $30-50/month for full coverage, or $0 if you only use free tiers + LM Studio",[41,44,47,50],{"q":42,"a":43},"Can't I just pick one AI coding tool?","Yes, but you'll be handicapped. Each tool has genuine strengths - Claude Code's MCP for terminal work, Cursor's codebase indexing, Copilot's autocomplete speed. Using one exclusively means missing out on what the others do best.",{"q":45,"a":46},"Is Claude Code worth it over just using ChatGPT?","If you do terminal work, refactors spanning 5+ files, or want MCP integrations (browser automation, docs, local tools), absolutely. If you just want chat assistance, ChatGPT is cheaper.",{"q":48,"a":49},"Why use LM Studio when cloud tools are faster?","Three reasons: privacy (code never leaves your machine), offline capability, and zero recurring cost. I use it for client work with NDAs and when traveling without reliable internet.",{"q":51,"a":52},"Which tool should I start with as a beginner?","GitHub Copilot. It's $10/month, works in any editor, and teaches you patterns through autocomplete. Add Claude Code when you're doing multi-file refactors. Add Cursor when you need better codebase understanding.","\"Which AI coding tool should I use?\" is the wrong question.\n\nI've burned through $50+/month on AI subscriptions for over a year now. Claude Pro. Cursor Pro. GitHub Copilot. Even ran local LLMs on my M1 Max when I didn't trust cloud providers with client code.\n\nThe real question isn't which one to pick. It's which one to reach for in each situation. Because trying to force Cursor to do what Claude Code does best, or expecting Copilot to handle complex refactors, is just making your life harder.\n\n## The Four Tools (And Their Actual Philosophies)\n\n**Claude Code** is a terminal-first agent. It lives in your shell, sees your file tree, and can run commands. It's built for complex multi-step tasks where you need something to read 10 files, modify 5, run tests, and adjust based on failures. The MCP (Model Context Protocol) support means it can control browsers, fetch docs, and integrate with local tools.\n\n**Cursor** is VS Code with AI that actually understands your codebase. It indexes your files and gives you GPT-4 or Claude chat directly in the editor. Best for exploratory work when you're asking \"where does this function get called?\" or \"why is this hook re-rendering?\"\n\n**GitHub Copilot** is still the autocomplete king. It predicts what you're typing next, usually correctly. The tab-tab-tab flow for writing boilerplate is unmatched. It's not trying to be your pair programmer - it's trying to save you from typing the same useState pattern for the 500th time.\n\n**LM Studio** is local, free, and private. You download models (Llama, Mistral, etc.) and run them on your machine. Slower than cloud tools. No fancy integrations. But your code never touches someone else's server, it works on planes, and it costs zero dollars ongoing.\n\n## When I Reach for Claude Code\n\nComplex refactors where I need to touch 5+ files. Yesterday I asked it to migrate my Next.js blog from runtime MDX parsing to build-time JSON generation. It:\n\n- Modified the content loading logic\n- Updated the blog page component\n- Created a build script to generate JSON\n- Updated package.json scripts\n- Tested the build locally\n\nI gave it one prompt. It executed 15 file operations and ran validation commands. That's what terminal-based agents excel at - multi-step workflows where each step depends on the previous one succeeding.\n\nI also use Claude Code when I need MCP integrations. The Playwright MCP lets it automate browser testing. The Context7 MCP pulls latest docs for frameworks. The Next.js DevTools MCP reads my dev server errors directly.\n\nCursor can't do this. Copilot definitely can't. Claude Code's terminal access and MCP ecosystem make it the only real option for these workflows.\n\n**Downside:** It requires Claude Pro ($20/mo) or Claude Max ($100/mo) subscription, or API credits. No free tier. And if you mess up the initial prompt, you're watching it make wrong edits across multiple files before you can course-correct.\n\n## When I Reach for Cursor\n\nExploring codebases I didn't write. I'm in a 50k+ line Next.js monorepo and need to understand how auth flows work. Cursor's `Ctrl+K` lets me select files, ask questions, and get answers grounded in actual code.\n\nI also use Cursor when I want chat but don't want to leave my editor. It's fast, the context is automatic (it sees your open files), and Claude or GPT-4 responses stream directly in the sidebar.\n\nFor rapid iteration - make change, ask AI to review, adjust, repeat - Cursor's inline chat beats copying code into ChatGPT. The feedback loop is tighter.\n\n**Downside:** It's a VS Code fork. If you use Vim, Emacs, or JetBrains IDEs, you're switching editors or giving up Cursor. The Pro plan is $20/month and limits how many slow/fast model requests you get. I've hit the limit during heavy refactor days.\n\n## When I Reach for Copilot\n\nWriting boilerplate. React components. API routes. TypeScript interfaces. Anything where the pattern is obvious and I'm just translating intent into syntax.\n\nCopilot's autocomplete flow is unmatched: type the function name, tab to accept the signature, tab to accept the body, done. No chat needed. No waiting for a model to think. It predicts, you accept, you move on.\n\nI also keep Copilot active when using Claude Code or Cursor. They handle complex tasks; Copilot handles the \"I need to import this but don't want to type the full path\" micro-moments.\n\n**Downside:** It's not smart enough for architecture decisions or complex logic. It hallucinates APIs that don't exist. It auto-completes confidently wrong code. You need to read what it suggests. The GitHub requirement also means your code metadata goes to Microsoft (anonymized, but still).\n\n## When I Still Use LM Studio\n\nClient projects under NDA. I literally cannot send their code to Anthropic or OpenAI without violating agreements. LM Studio + a local Mistral or Llama model lets me get AI assistance without uploading anything.\n\nWorking offline. Flights. Coffee shops with bad wifi. My machine, my models, my code. Cloud tools are useless here.\n\nCost-sensitive personal projects. If I'm building a hobby app and don't want to pay $50/month in AI subscriptions, LM Studio is free. I download a 7B parameter model, run it locally, and get decent (if slower) assistance.\n\n**Downside:** It's slow. A response that takes Claude 3 seconds takes Llama 3 70B on my M4 Pro (48GB) around 15-20 seconds. The quality is worse - local models aren't as smart as frontier cloud models. And you need a beefy machine (16GB+ RAM for decent performance).\n\nCheck out my [full LM Studio setup guide](/blog/lm-studio-local-llm-setup-guide) if you want to run local LLMs for private or offline development.\n\n## The Honest Downsides\n\n**Claude Code:**\n- Expensive ($20-100/mo subscription or API usage)\n- Terminal-only means no GUI editor integration\n- Can spiral into wrong edits if initial prompt is unclear\n- MCP ecosystem is still immature\n\n**Cursor:**\n- Forces you into their VS Code fork (vendor lock-in)\n- $20/month Pro plan has usage caps that bite during heavy use\n- Codebase indexing can be slow on huge monorepos\n- Free tier is limited enough to be frustrating\n\n**GitHub Copilot:**\n- Autocomplete only - no complex reasoning or refactoring\n- Hallucinates APIs and patterns confidently\n- Owned by Microsoft (if that matters to you)\n- Individual plan is $10/mo, Business is $19/mo (more cost)\n\n**LM Studio:**\n- Slow compared to cloud models\n- Lower quality responses than frontier models\n- Requires beefy hardware (32GB+ RAM ideal, 48GB+ for 70B parameter models)\n- No cloud features like web search or real-time docs\n\n## My Actual Daily Workflow\n\nMorning: Open Cursor. Scan overnight changes. Ask it \"what did this PR change and why?\" to catch up on team work.\n\nDevelopment: Copilot handles autocomplete. When I need to refactor something complex (moving components, updating types across files), I switch to Claude Code in terminal.\n\nResearch: Need latest Next.js 15 patterns? Claude Code with MCP docs integration. Need to understand how a specific function works in this codebase? Cursor chat.\n\nClient work: LM Studio only. Download Mistral 7B, use it for code review and simple refactors. Slower, but I'm not risking NDA violations.\n\nLate night personal projects: As an ASU CS grad student, I get Copilot free via GitHub Education + LM Studio. Zero monthly cost, decent quality, no guilt about burning subscription credits.\n\n## Cost Breakdown\n\n| Tool | Monthly Cost | What You Get |\n|------|-------------|--------------|\n| **Claude Code** | $20 (Pro) or $100 (Max) | Terminal agent + MCP integrations, higher usage limits on Max |\n| **Cursor** | $20 (Pro) | AI-powered VS Code fork, codebase indexing, limited fast requests |\n| **GitHub Copilot** | $10 (Individual) or $19 (Business) | Autocomplete in any editor, chat interface |\n| **LM Studio** | $0 | Local models, unlimited usage, privacy, offline capability |\n\n**Full Stack:** $50/month (Claude Pro + Cursor Pro + Copilot)\n**Budget Stack:** $10/month (Copilot only) + LM Studio free\n**Privacy Stack:** $0/month (LM Studio only, or Copilot if you already have GitHub access)\n\nHonestly? I pay the $50. I'm building 30+ projects and working on a master's degree. The time saved is worth more than the cost. But if I were a student without income, I'd use Copilot + LM Studio and be fine.\n\n## The Bottom Line\n\nDifferent tools for different jobs. Claude Code owns complex terminal workflows and MCP-powered integrations. Cursor dominates in-editor exploration and codebase questions. Copilot is still the autocomplete king. LM Studio covers privacy and offline needs.\n\nTrying to use just one is like using only a hammer because you don't want to carry a screwdriver. It works until you hit a screw.\n\nI use all three cloud tools daily. I keep LM Studio ready for sensitive work. The combined workflow is faster than forcing any single tool to do everything.\n\nYour mileage will vary based on what you build. If you're writing simple scripts, Copilot alone is fine. If you're refactoring production codebases, you need Claude Code or Cursor. If you're under NDAs or traveling constantly, you need LM Studio.\n\nPick your poison based on your actual workflow, not what YouTube influencers say is \"best.\" Test each tool for a month. Track which one you actually reach for in different situations. Then pay for what you use and ignore the rest.\n\nThat's it. No magic answer. Just different tools that happen to be good at different things.","src/content/blog/ai-coding-tools-compared-2025.mdx","0bd8c8f9702585c0","ai-coding-tools-compared-2025.mdx","pickmyclass-never-miss-your-dream-class",{"id":57,"data":59,"body":97,"filePath":98,"digest":99,"legacyId":100,"deferredRender":31},{"title":60,"date":61,"excerpt":62,"tags":63,"published":31,"author":32,"tldr":74,"keyTakeaways":75,"faq":81},"PickMyClass: Never Miss Your Dream Class Again","2025-10-28","How I built a class notification system that watches for open seats and instructor updates, so students never miss their dream classes due to constant refreshing.",[64,65,66,67,68,69,70,71,72,73],"Side Project","Puppeteer","Web Scraping","Next.js","Cloudflare Workers","Supabase","ASU","College","SaaS","Full Stack","PickMyClass is a notification system that monitors ASU class availability every 30 minutes and emails students when seats open or instructors are assigned, serving 10,000+ users for $34/month.",[76,77,78,79,80],"Built to solve personal frustration with missing class seats at 2 AM","Uses Puppeteer on Oracle Cloud to scrape JavaScript-rendered pages","Scales to 10,000 users at $0.0034 per student per month","Real-time updates via Supabase subscriptions","2,500x database query reduction through batch optimizations",[82,85,88,91,94],{"q":83,"a":84},"How often does PickMyClass check for open seats?","Every 30 minutes. This balances timely notifications with responsible server load on ASU's systems.",{"q":86,"a":87},"Why use Puppeteer instead of direct API calls?","ASU's class search loads data with JavaScript and returns 401 errors without proper browser context. Puppeteer simulates a real Chrome browser to fetch the data successfully.",{"q":89,"a":90},"How much does it cost to run PickMyClass at scale?","About $34/month for 10,000 users. That breaks down to Oracle Cloud free tier for Puppeteer, Cloudflare Workers, Supabase, and Resend for emails.",{"q":92,"a":93},"Can PickMyClass work for other universities?","The architecture is designed to be adaptable. Any school with a web-based class search can be supported with a new scraper configuration.",{"q":95,"a":96},"How do you handle rate limiting and anti-bot detection?","Circuit breaker patterns prevent cascading failures. The scraper uses realistic browser fingerprints and respects rate limits to avoid being blocked.","## The Story Behind the Build\n\nPicture this: It's 3 AM. You're refreshing the ASU class search page for the hundredth time. That coding class you need to graduate? Still full. The professor everyone raves about? Still listed as \"Staff.\"\n\nSound familiar? It happened to me during my sophomore year.\n\nI needed CSE 310 with Professor Martinez. The class was full. I set phone alarms every hour. I checked between classes. I even woke up in the middle of the night to refresh the page. When a seat finally opened at 2:47 AM on a Tuesday, I was asleep. Someone else got it.\n\nThat's when I remembered pickaclass.app—a tool that watched classes for you. It sent emails when seats opened up. Perfect solution, right? Except it shut down in 2023.\n\nSo I built my own.\n\n## What PickMyClass Does\n\n[PickMyClass](https://pickmyclass.app) is a notification system for university students. Enter your section number, and the app does the watching for you.\n\nThe system checks every 30 minutes for two things:\n\n- **Open seats** – Get notified the moment a full class has availability\n- **Instructor updates** – Know when \"Staff\" changes to an actual professor name\n\nNo more constant refreshing. No more missed opportunities. Just an email when something changes.\n\n## The Architecture\n\nHere's how the system flows:\n\n```\nUser Request → Cloudflare Worker (Edge)\n                    ↓\n              Supabase (Auth + DB)\n                    ↓\n            Cloudflare Queue (Job)\n                    ↓\n        Oracle Cloud (Puppeteer Scraper)\n                    ↓\n              Supabase (Update DB)\n                    ↓\n            Resend API (Email Notification)\n```\n\nThe architecture keeps costs low: Cloudflare handles edge logic for free, Oracle's always-free tier runs the heavy Puppeteer work, and Supabase's generous free tier stores user data.\n\n## The Technical Challenge\n\nBuilding this wasn't straightforward. ASU's class search loads data with JavaScript. Their API returns 401 errors without browser context. Simple HTTP requests don't work.\n\nThe solution? A Puppeteer-based scraper running on Oracle Cloud. It uses a real Chrome browser to fetch class data.\n\nHere's the core scraping logic:\n\n```typescript\n// Wait for the class results to load\nawait page.waitForSelector('.class-results-row', { timeout: 30000 });\n\n// Extract class data from the page\nconst classData = await page.evaluate(() => {\n  const rows = document.querySelectorAll('.class-results-row');\n  return Array.from(rows).map(row => ({\n    sectionNumber: row.querySelector('.section-id')?.textContent?.trim(),\n    seatsAvailable: parseInt(\n      row.querySelector('.seats-open')?.textContent || '0'\n    ),\n    instructor: row.querySelector('.instructor-name')?.textContent?.trim()\n      || 'Staff',\n  }));\n});\n```\n\nThe tricky part? Handling authentication cookies, session timeouts, and random 401 errors. Circuit breaker patterns prevent one failed request from crashing everything.\n\n## The 2,500x Query Optimization\n\nInitially, each class check triggered individual database queries. With 10,000 users watching 3 classes each, that's 30,000 queries per cron run. Unacceptable.\n\nThe fix: batch everything.\n\n```sql\n-- Before: Individual queries per class (30,000 queries)\nSELECT * FROM watches WHERE section_id = $1;\n\n-- After: Single batch query (1 query)\nSELECT section_id, array_agg(user_id) as watchers\nFROM watches\nWHERE section_id = ANY($1)\nGROUP BY section_id;\n```\n\nOne query fetches all watches. One query updates all changes. The email API supports batch sends. Total queries dropped from 30,000 to under 12.\n\n## Cost Breakdown at Scale\n\nHere's what it costs to run PickMyClass for 10,000 users:\n\n| Service | Monthly Cost | Notes |\n|---------|-------------|-------|\n| Oracle Cloud | $0 | Always-free tier for Puppeteer VM |\n| Cloudflare Workers | ~$5 | Beyond free tier at scale |\n| Supabase | $25 | Pro tier for reliability |\n| Resend | ~$4 | Email volume pricing |\n| **Total** | **~$34** | **$0.0034 per user** |\n\nCompare that to a traditional AWS setup that would run $200-500/month for the same workload.\n\n## Working With (Not Against) ASU's Systems\n\nWeb scraping has ethics. Here's how PickMyClass stays responsible:\n\n1. **30-minute intervals** – Not hammering their servers every minute\n2. **Request queuing** – Max 5 concurrent scraper instances\n3. **Exponential backoff** – Failed requests wait longer before retry\n4. **User-Agent honesty** – Not pretending to be Googlebot\n5. **Circuit breakers** – If ASU is having issues, we stop trying temporarily\n\nThe goal is to be a good citizen. If everyone scraped irresponsibly, they'd block everyone.\n\n## Built With Modern Web Tech\n\nThe stack includes:\n\n- Next.js 15 for the frontend\n- Cloudflare Workers for edge computing\n- Supabase for authentication and real-time features\n- PostgreSQL with row-level security\n- Puppeteer for web scraping\n- Resend for transactional emails\n\nThe dashboard updates live. Add a class watch, and it appears instantly. When the cron job detects changes, your browser sees them without refreshing.\n\n## Why It Matters\n\nGetting into the right class can change your college experience. The right professor makes difficult subjects click. Required courses at convenient times let you work or do internships. Popular electives fill up in minutes.\n\nStudents shouldn't lose opportunities because they were in class or asleep. Technology should work for us, not against us.\n\n[PickMyClass](https://pickmyclass.app) levels the playing field. Whether you're a morning person or a night owl, you get the same chance at that open seat.\n\n## What I Learned\n\nThis project taught me how to:\n\n- Build fault-tolerant systems at scale\n- Work with headless browsers and anti-bot measures\n- Design database schemas with security policies\n- Implement edge caching for performance\n- Handle webhook integrations for email delivery\n\nBut the biggest lesson? Solve problems you actually have. The best projects come from real frustrations. When you've experienced the problem firsthand, you know exactly what the solution needs to do.\n\n## Looking Forward\n\n[PickMyClass](https://pickmyclass.app) is live and watching classes right now. The system currently supports ASU, but the architecture works for any school with a web-based class search.\n\nNeed to track a class at your university? Visit [pickmyclass.app](https://pickmyclass.app) to get started. The notification system is designed to be adaptable to different institutions with similar class registration challenges.","src/content/blog/pickmyclass-never-miss-your-dream-class.mdx","6cedb23c74fdd938","pickmyclass-never-miss-your-dream-class.mdx","authenticity-paradox-online-persona",{"id":101,"data":103,"body":137,"filePath":138,"digest":139,"legacyId":140,"deferredRender":31},{"title":104,"date":105,"dateModified":16,"excerpt":106,"tags":107,"published":31,"author":32,"tldr":117,"keyTakeaways":118,"faq":124},"The Developer's Authenticity Paradox: Why Success Feels Like Performance","2025-12-07","The authenticity paradox explained: why your online persona diverges from your real self. Psychology research + my experience with 500k users and daily metrics obsession.",[108,109,110,111,112,113,114,115,116],"Authenticity","Psychology","Social Media","Personal Growth","Developer Life","Mental Health","Identity","Imposter Syndrome","Developer Burnout","Online authenticity is a paradox - the more you try to be 'real,' the more you perform. After honestly examining my metrics obsession, platform personas, and the gap between my LinkedIn self and actual self, I realized the only authenticity available might be knowing you're playing a game.",[119,120,121,122,123],"The 'authenticity paradox': striving to be authentic online makes authenticity unreachable","Metrics (stars, followers, views) can literally control your mood if you let them","Different platforms create different versions of you - and none of them are the 'real' one","Caring about everything isn't weakness - it's awareness of human complexity","The only honest move might be admitting you're performing while you perform",[125,128,131,134],{"q":126,"a":127},"What is the authenticity paradox?","Research shows that to appear 'authentic' online, you must share vulnerable or negative experiences - but doing so has social costs. The very act of presenting authenticity becomes a performance, making true authenticity either unreachable or only possible at great personal cost.",{"q":129,"a":130},"Why do I feel behind when I see others' success on social media?","Social comparison on platforms like LinkedIn and Twitter triggers anxiety because you're comparing your full internal experience (doubts, struggles, mundane days) to others' curated highlights. Studies show this is universal - even successful people feel it.",{"q":132,"a":133},"Is it bad to check metrics like GitHub stars or LinkedIn views?","Not inherently, but when metrics 'decide your mood' daily, it becomes problematic. The feedback loop of external validation can disconnect you from internal values and make your self-worth contingent on numbers you can't fully control.",{"q":135,"a":136},"Can you be authentic online while maintaining a professional presence?","Partially. You can be selectively authentic - sharing real experiences without sharing everything. But full authenticity requires vulnerability that most professional contexts punish. The key is being aware of what you're choosing to show and why.","I have 500,000 users on a project I built. I learned an entire programming language by reading documentation on my phone. I migrated a codebase from Python to Go using StackOverflow answers and sheer stubbornness.\n\nAnd yesterday, I spent 20 minutes refreshing my GitHub profile to see if my star count changed.\n\nThis is the authenticity paradox: the gap between what I've actually accomplished and how I feel about it. Between who I am online and who I am when nobody's watching. Between the version of me that exists on LinkedIn and the version that exists in my group chats with friends.\n\nI'm not sure which one is real anymore. And I suspect I'm not alone in this digital identity crisis.\n\nThis is a specific flavor of **developer imposter syndrome** where the better you look on paper, the more fraudulent you feel. It's the **social media anxiety** that comes from comparing your internal chaos to everyone else's highlight reel.\n\n## The Metrics Trap: How GitHub and LinkedIn Impact Developer Mental Health\n\nHere's my morning routine that I'm not proud of:\n\n- **Wake up, grab phone**\n- **Check GitHub** - did anyone star my repos overnight?\n- **Check Google Search Console** - how's my portfolio ranking?\n- **Check LinkedIn** - any new followers, any engagement on posts?\n- **Check Instagram** - just to see what everyone else is doing\n\nThis takes maybe 15 minutes. Sometimes 30 if I start doom-scrolling.\n\nThe numbers affect my mood for the rest of the day. Up? I feel validated, like I'm on the right track. Down or flat? Something's wrong. I'm not doing enough. I'm falling behind.\n\nI know this is unhealthy. The rational part of my brain understands that GitHub stars don't determine my worth as a developer. That LinkedIn followers don't correlate with actual skill. That Instagram engagement is literally designed to be addictive.\n\nBut knowing something and feeling it are different things.\n\nThe worst part is scrolling Twitter (I refuse to call it X) and seeing people in San Francisco announce their seed rounds. \"Excited to announce we've raised $2M to revolutionize [something].\" Meanwhile, I'm sitting in my apartment in Arizona, a grad student at ASU, wondering if I'm wasting my potential.\n\n[Research backs this up](https://www.tandfonline.com/doi/full/10.1080/17459435.2025.2539115): A 2025 study found that people spending 5-6 hours daily on social platforms still reported feeling socially isolated. The researchers identified something called the \"authenticity-visibility paradox\" - as users become more visible online, they present less authentic versions of themselves, which undermines genuine connection.\n\nMore visibility. Less authenticity. More loneliness. The social media comparison trap is real, and we're all falling into it.\n\n## The Curated Self: Balancing Online Persona and Real Identity\n\nI grew up in India. The path was clear: get good grades, get a job, maybe join the family business. Success meant stability. Ambition meant not rocking the boat too much.\n\nThen I moved to the US for my Master's. I lived with my uncle, and everything changed.\n\nMy uncle is a businessman. Real estate, restaurants, investments. Living with him, I absorbed a completely different worldview: you can build anything. If you don't know how to do something, you hire someone who does. Money is a tool. Scale is possible.\n\nThis wasn't the mindset I grew up with. It was exciting and terrifying.\n\nNow I'm a mixture of both worlds. I visit India two or three months a year. I have friends there who know a version of me that my American friends have never seen. And I have friends here who know a version of me that my Indian friends wouldn't recognize.\n\nIt gets more fragmented online:\n\n**LinkedIn/GitHub me**: Serious tech guy. Projects with impressive user counts. Contributions to open source. Professional headshot. \"Passionate about building scalable systems.\" (I even wrote a [Claude vs Cursor vs Copilot comparison](/blog/ai-coding-tools-compared-2025) because that's what serious tech guys do, apparently.)\n\n**Instagram/Snapchat me**: Fun. Friends. Car meets. New restaurants. Memories that stay in the group chat and never become \"content.\"\n\n**Portfolio me**: The \"landing page\" version. Curated highlights. The person I want you to find when you Google my name.\n\nMy close friends - the ones who actually know me - say something that sticks with me: \"He's knowledgeable, but he's not the person you see online.\"\n\nThey're right. And I don't know how to fix that. This gap between my online persona and real life self keeps widening.\n\n[Psychology Today calls this \"the curated self\"](https://www.psychologytoday.com/us/blog/202302/the-curated-self) - the selection, organization, and presentation of online content about yourself. They quote something that haunts me: \"As the virtual self takes over, the real self is displaced.\"\n\nWe curate our lives around perceived perfection because we're rewarded with hearts, likes, and thumbs up. The feedback loop trains us to show more of what gets engagement and less of what doesn't. Eventually, even we forget which parts are real.\n\n## Developer Imposter Syndrome: Why Success Feels Like a Performance\n\nLet me tell you about [Alita Robot](https://github.com/divkix/alitarobot).\n\nIt's a Telegram bot for group management. I built it originally in Python, but I wanted to learn Go. So I rewrote the entire thing - not because Python wasn't working, but because I wanted to challenge myself.\n\nI learned Go by reading documentation on my phone. I had an Android with a terminal shell installed, and I'd code on the bus, in waiting rooms, whenever I had downtime. I scoured StackOverflow for answers. I made mistakes, broke things, fixed them, broke them again. (If you're curious about how I approach learning new tech, I wrote about my [my 2025 developer tools and stack](/blog/side-project-stack-2025-grad-student).)\n\nEventually, it worked. The bot grew. 500,000 users.\n\nHere's the thing: sharing that number feels performative.\n\nBecause when I say \"500k users,\" you picture success. You picture someone who had a plan, executed it flawlessly, and reaped the rewards.\n\nYou don't picture the mess. The bugs I shipped at 2am that broke everything. The hours I spent trying to understand why something wasn't working. The nights I almost gave up. The imposter syndrome when someone asked how I built it and I wanted to say \"honestly, I have no idea how it works half the time.\"\n\nThe highlight reel erases the messy middle. This is the core of developer imposter syndrome - we see everyone's polished output and compare it to our chaotic process.\n\nThis is why I've started valuing small, authentic circles over large, visible ones. I've been in friend groups that looked great from the outside but were full of drama and fakeness internally - people being nice to each other's faces while talking shit behind backs. I left those groups.\n\nThe friends I have now are different. We're real with each other. We don't perform. And none of that makes it to Instagram.\n\n## The Psychology of Caring Too Much in a \"Don't Give a F*ck\" World\n\nI read Mark Manson's \"The Subtle Art of Not Giving a F*ck.\" You know the premise: you have a limited number of fucks to give in your lifetime. Choose them wisely. Stop caring about things that don't matter.\n\nGreat advice. I believe it intellectually.\n\nI still care about everything.\n\nNot in a anxious, spiral-out-of-control way (usually). More in a... I notice things way. How people react. What makes them uncomfortable. The small moments that seem insignificant but might actually matter.\n\nHumans are sophisticated. What seems like a throwaway comment can scar someone. What looks like a small gesture can make someone's day. I don't want to miss those moments.\n\nThis creates tension with the \"limited fucks\" philosophy. If I care about everything, aren't I wasting my fuck budget?\n\nI don't think so. I think there's a difference between caring and being consumed. I can notice how someone feels without letting it derail my entire day. I can be aware of human complexity without losing myself in it.\n\nThis connects to why I want to be a social entrepreneur, not just an entrepreneur. Building something isn't enough for me. I want to build something that actually helps people. That changes lives. The business mindset my uncle taught me - scale, hire talent, move fast - is valuable. But it's not the destination. It's a tool for impact.\n\nThe tension I feel daily: I want to go big. I want to be known. I see those SF founders on Twitter and feel the pull of that world. But I also want to take walks. Go to car meets. Try new restaurants with friends. Be present.\n\nMaybe the answer isn't choosing one or the other. Maybe it's holding both, uncomfortably, and seeing what happens. Maybe authentic self online is just another myth we've been sold.\n\n## The Authenticity Paradox of Personal Branding\n\nI built this portfolio - the site you're reading right now - so that when something I make blows up, people can find me. They can Google my name and see the full picture.\n\nBut which \"full picture\"?\n\nThe portfolio version of me is still curated. I chose which projects to highlight. I wrote the bio. I selected which blog posts to publish (like this one - is this authentic, or is writing about authenticity just another performance?).\n\n[Research from ACM](https://dl.acm.org/doi/abs/10.1145/3479567) calls this the \"online authenticity paradox\": people strive to achieve online authenticity, yet because doing so requires sharing negative experiences on social media, online authenticity is often unreachable - or is possible only at great personal cost.\n\nTo be seen as authentic, you have to be vulnerable. But vulnerability online has consequences. Employers see your posts. Investors Google you. That hot take might haunt you.\n\nSo we perform authenticity instead. We share struggles, but only the ones that make us look good in hindsight. We admit failures, but only after we've recovered from them. We're \"real,\" but in a very controlled way.\n\nAnother researcher put it perfectly: authenticity on social media is \"an unrepeatable temporary interval\" - a moment that passes, never fully achievable, always slipping away.\n\n## Living With the Digital Identity Paradox\n\nI don't have a solution to this.\n\nI'm not going to tell you I've found balance or that I've stopped checking my metrics (I checked Cloudflare Analytics twice while writing this post). I'm not going to pretend I've resolved the tension between my India self and my US self, or that my online persona and real self have finally merged into one authentic whole.\n\nThey haven't.\n\nWhat I'm trying instead:\n\n**Keeping the real stuff in group chats.** Not everything needs to be content. Some memories are better when they stay between friends.\n\n**Accepting that metrics will affect my mood.** Fighting it is exhausting. Noticing it is easier. \"Oh, I'm feeling anxious because my star count dropped. Interesting. Anyway.\"\n\n**Staying in authentic circles.** The fake friend groups aren't worth it. The small, real ones are everything.\n\n**Admitting I'm performing.** Even this blog post is a performance. I chose what to share and what to leave out. But at least I know I'm doing it.\n\nMaybe that's the only authenticity available: knowing you're playing a game while you play it.\n\nThe metrics will probably decide my mood tomorrow. I'll probably check LinkedIn before I check anything else. I'll probably feel that pang of \"I'm behind\" when I see someone announce their funding round.\n\nBut I'll also probably go for a walk. Meet friends. Talk about things that will never become content. And in those moments, the paradox dissolves.\n\nNot because I've solved it. But because I've stopped trying to.\n\n---\n\n*If this resonated with you, I'd love to hear your experience. What's the gap between your online self and your real self? Hit me up on [Twitter](https://twitter.com/divkix) or [LinkedIn](https://linkedin.com/in/divkix) - though I'll admit the irony of asking for engagement on a post about the toxicity of engagement.*","src/content/blog/authenticity-paradox-online-persona.mdx","959548b6e3b73b55","authenticity-paradox-online-persona.mdx","lm-studio-local-ai-mac",{"id":141,"data":143,"body":195,"filePath":196,"digest":197,"legacyId":198,"deferredRender":31},{"title":144,"date":145,"excerpt":146,"tags":147,"published":31,"author":32,"tldr":156,"keyTakeaways":157,"faq":163,"howto":179},"Running AI on My Mac: Why I Ditched ChatGPT for LM Studio","2025-10-31","How I run powerful AI models locally on my M4 Pro MacBook with LM Studio. Privacy, speed, and vision models that can see images - all offline.",[19,23,148,149,150,151,152,153,154,155],"Privacy","Mac","Qwen","Local AI","M4 Pro","Vision Models","ChatGPT Alternative","Offline AI","LM Studio lets you run powerful AI models locally on Mac with Apple Silicon, offering complete privacy and no subscription costs, though it's slower than cloud alternatives.",[158,159,160,161,162],"LM Studio runs AI models locally with zero data leaving your machine","M4 Pro with 48GB RAM can run 30B parameter vision models like Qwen3-VL","Vision models understand screenshots, diagrams, and UI mockups","Costs $0 vs $240/year for ChatGPT Plus","Trade-offs: slower responses (5-10 sec), requires storage for models",[164,167,170,173,176],{"q":165,"a":166},"How much RAM do I need to run LM Studio?","Minimum 16GB for smaller 7B-8B models. 32GB+ recommended for 13B models. 48GB+ needed for 30B+ parameter models like Qwen3-VL-30B.",{"q":168,"a":169},"Is LM Studio really free?","Yes, completely free. No account, no credit card, no subscription. The models from Hugging Face are also free and open-source.",{"q":171,"a":172},"Can LM Studio analyze images and screenshots?","Yes, with vision-language models like Qwen3-VL. You can paste screenshots of code errors, UI designs, charts, or diagrams and the model will understand the visual context.",{"q":174,"a":175},"How does LM Studio compare to ChatGPT?","LM Studio is slower (5-10 seconds vs instant), works offline, has complete privacy, costs nothing, but lacks web browsing and real-time information. For daily coding and analysis work, it's highly capable.",{"q":177,"a":178},"What Mac models support LM Studio?","Any Mac with Apple Silicon (M1, M2, M3, M4). Performance scales with RAM and chip tier. M4 Pro/Max with 48GB+ RAM offers the best experience for large models.",{"name":180,"totalTime":181,"steps":182},"How to Set Up LM Studio on Mac","PT15M",[183,186,189,192],{"name":184,"text":185},"Download LM Studio","Go to lmstudio.ai and download the Mac installer. Open and drag to Applications.",{"name":187,"text":188},"Browse Available Models","Click 'Discover' tab. Search for 'Qwen3-VL-8B' for vision capabilities or 'Qwen-7B' for text-only.",{"name":190,"text":191},"Download a Model","Click download on your chosen model. Wait for download to complete (several GB).",{"name":193,"text":194},"Load and Chat","Click 'Load' to activate the model. Start chatting in the conversation interface.","I was knee-deep in a coding problem when ChatGPT went dark. The little error message mocked me. \"Try again later,\" it said. My deadline wasn't going to wait.\n\nThat outage was annoying. But it got me thinking. Every time I use ChatGPT, my data flies to OpenAI's servers. They log it. They train on it. Maybe that's fine for \"what's a good pizza recipe.\" But code snippets? Research notes? That felt wrong.\n\nI needed something different. Something local. Something mine.\n\n## The Cloud Problem No One Talks About\n\nHere's the thing about cloud AI. It's convenient. Type a question, get an answer. But convenience has a cost.\n\nYour prompts live on someone else's computer. They say they don't use it for training anymore. Maybe they don't. But can you be sure? What about government requests? Data breaches? Server logs?\n\nI'm not paranoid. I just value control. My Mac has plenty of power. Why send my data across the internet when I can process it right here?\n\n## How I Found LM Studio\n\nA friend mentioned LM Studio in passing. \"Run AI models on your Mac,\" he said. \"Totally free.\"\n\nI was skeptical. Local AI sounded slow. Complicated. Probably worse than the cloud versions.\n\nI downloaded it anyway. The install was simple. No account. No credit card. Just download and go.\n\nThe interface looked clean. Like a chat app, but with a model picker. I could browse thousands of open-source models. Download them. Run them locally.\n\nNo API keys. No monthly bills. No data leaving my machine.\n\n## My M4 Pro Makes This Possible\n\nI upgraded to an M4 Pro MacBook Pro earlier this year. 48GB of unified memory. At the time, I thought I'd gone overboard.\n\nTurns out, that RAM is perfect for AI. Most people run smaller models. Maybe 8B parameters. Those work fine on 16GB machines.\n\nBut with 48GB? I can run Qwen3-VL-30B. That's a big model. A smart model. And it can do something most AI tools can't.\n\nIt can see.\n\n## Model Recommendations by RAM\n\nNot sure which model to run? Here's what works at different RAM levels:\n\n| RAM | Best Models | Use Case |\n|-----|-------------|----------|\n| 16GB | Qwen-7B, Llama-8B, Mistral-7B | Basic chat, simple coding questions |\n| 32GB | Qwen-14B, Llama-13B, Deepseek-Coder-6.7B | Complex reasoning, longer context windows |\n| 48GB+ | Qwen3-VL-30B, Llama-70B (quantized), CodeLlama-34B | Vision models, advanced analysis, code generation |\n\nMore RAM means bigger models. Bigger models mean better reasoning. It's that simple.\n\n## Vision Models Changed Everything\n\nQwen3-VL is a vision-language model. Feed it text, it responds. Feed it an image, it understands that too.\n\nLast week I got a weird error in my terminal. Red text everywhere. I took a screenshot. Pasted it into LM Studio. Asked \"what's wrong here?\"\n\nThe model looked at my screenshot. Pointed out the exact line causing trouble. Explained why. Suggested a fix.\n\nHere's the kind of prompt that works:\n\n> Look at this terminal screenshot. The red error text starts with \"TypeError\". What's causing this and how do I fix it?\n\nAnd the model responds with context-aware analysis:\n\n> The error \"TypeError: Cannot read properties of undefined\" on line 47 indicates you're trying to access a property on a variable that wasn't initialized. Check that `userData` is defined before calling `userData.profile.name`. Add a null check or optional chaining: `userData?.profile?.name`.\n\nThis isn't OCR. The model actually understands visual context. Diagrams. Charts. UI mockups. Code screenshots with syntax highlighting intact.\n\nI also run the smaller Qwen3-VL-8B. It's faster. Good for quick questions. But the 30B model? That's where the magic happens. Complex reasoning. Better context. More accurate answers.\n\nMost people can't run 30B models. Not enough RAM. I can. That's my edge.\n\n## Speed Comparison: Cloud vs Local\n\nLet's be honest about performance. Here's what I measured:\n\n| Task | ChatGPT | LM Studio (Qwen-30B) |\n|------|---------|---------------------|\n| Simple question | ~1 sec | ~5 sec |\n| Code explanation (100 lines) | ~2 sec | ~10 sec |\n| Image analysis | ~3 sec | ~15 sec |\n| Long document summary | ~4 sec | ~20 sec |\n\nThe slower speed is the main trade-off. But here's the thing—I've found it rarely matters for actual work. While waiting 10 seconds for a response, I'm reading the question I just asked. By the time I look up, the answer is there.\n\n## What I Actually Use It For\n\nEvery day looks different. Sometimes I'm researching a new library. I paste documentation. Ask questions. The model helps me understand faster than reading alone.\n\nOther times I'm experimenting. Testing prompts. Trying different models. Seeing what works. LM Studio makes this easy. Switch models with one click.\n\nI've used it for code reviews. Explaining legacy code. Brainstorming architecture. Even writing. The AI isn't perfect. But it's always there. Always private.\n\nYesterday I analyzed a competitor's UI design. Screenshot → LM Studio → detailed breakdown of their layout choices. All offline. No one tracking what I'm researching.\n\nThat's the real win. Privacy isn't about hiding. It's about control.\n\n## Alternatives I Considered\n\nLM Studio isn't the only option. Here's how it compares:\n\n- **Ollama** – Command-line focused, no built-in GUI. Great for devs who prefer terminal. Excellent for automation and scripting.\n- **GPT4All** – Simpler UI, fewer models, easier for beginners. Good starting point if LM Studio feels overwhelming.\n- **Jan.ai** – Similar to LM Studio, newer project, currently has fewer model options. Worth watching.\n\nI picked LM Studio for the model variety and vision model support. The interface is clean. The model selection is massive. And it just works.\n\n## The Honest Downsides\n\nLM Studio isn't perfect. Let me be real about the problems.\n\nFirst, it's slower than ChatGPT. Cloud models have massive GPU clusters. My Mac has... one M4 Pro. Responses take longer. Maybe 5-10 seconds instead of instant.\n\nSecond, you manage everything yourself. Want a new model? Download it. That's a few gigabytes. Models pile up fast. You'll need storage space.\n\nThird, there's a learning curve. Which model for which task? What's the difference between 7B and 70B? You have to learn this stuff.\n\nThe interface is simpler than the web version of ChatGPT. No plugins. No browsing. Just you and the model.\n\nFor some tasks, cloud AI still wins. Web search? Up-to-date info? Yeah, ChatGPT is better there.\n\n## Why I Keep Using It Anyway\n\nBecause my data stays mine.\n\nBecause I don't need internet to think.\n\nBecause I'm not paying per token.\n\nI ran the numbers. ChatGPT Plus is $20/month. That's $240/year. LM Studio is free. The models are free. I paid for the Mac anyway.\n\nWhen my internet goes down, LM Studio still works. When OpenAI has an outage, I don't care. When they change their pricing, doesn't affect me.\n\nI'm not locked into their ecosystem. Don't like Qwen? Try Llama. Or Mistral. Or Deepseek. Or whatever comes next week.\n\nOpen source moves fast. Really fast. Models improve constantly. And they're all free.\n\n## Getting Started Is Easier Than You Think\n\nGo to lmstudio.ai. Download the app. Open it.\n\nClick \"Discover\" to browse models. Search for \"Qwen3-VL-8B\" if you want to try vision. Or \"Qwen-7B\" for text-only.\n\nDownload a model. Wait. It's big. Go make coffee.\n\nOnce downloaded, click \"Load.\" Pick your model. Start chatting.\n\nThat's it. Seriously.\n\nIf you have a Mac with Apple Silicon, you're golden. 16GB RAM minimum. More is better. Windows and Linux work too.\n\nThe models live at Hugging Face. Thousands of them. Some good. Some bad. LM Studio shows you ratings and downloads to help pick.\n\n## My Final Take\n\nI still use ChatGPT sometimes. It has its place. But for daily work? LM Studio wins.\n\nThe M4 Pro with 48GB was expensive. But running serious AI models locally? That alone justifies the cost. The vision models are a game-changer. Most people don't realize what's possible.\n\nIf you care about privacy, try it. If you hate subscriptions, try it. If you just want to own your tools, try it.\n\nYour data belongs to you. Not to some company's training dataset.\n\nDownload LM Studio. Pick a model. See what local AI can do.\n\nYou might not go back.","src/content/blog/lm-studio-local-ai-mac.mdx","09259dafa55037f5","lm-studio-local-ai-mac.mdx","zero-cost-portfolio-cloudflare-workers",{"id":199,"data":201,"body":248,"filePath":249,"digest":250,"legacyId":251,"deferredRender":31},{"title":202,"date":15,"excerpt":203,"tags":204,"published":31,"author":32,"tldr":212,"keyTakeaways":213,"faq":219,"howto":232},"How I Host My Portfolio for $0/Month on Cloudflare","Zero hosting costs, global edge deployment, and sub-50ms response times. Here's how I run divkix.me on Cloudflare Workers with Next.js 15 and why you should consider ditching Vercel.",[68,67,205,206,207,208,209,210,211,28],"Edge Computing","Serverless","Free Hosting","OpenNext","Portfolio","Web Development","Cost Optimization","I host my Next.js portfolio on Cloudflare Workers completely free using OpenNext, getting global edge deployment and zero cold starts without paying Vercel's premium.",[214,215,216,217,218],"Cloudflare Workers free tier: 100K requests/day with zero bandwidth limits beats Vercel's 100GB cap","V8 isolates mean 5ms cold starts vs 200-500ms for traditional serverless functions","OpenNext adapter makes Next.js work on edge runtime with minimal config changes","Edge runtime constraints require prebuild strategy - no filesystem access at runtime","Global deployment to 330+ cities happens automatically without multi-region setup",[220,223,226,229],{"q":221,"a":222},"Can I use Next.js App Router with Cloudflare Workers?","Yes, but with constraints. Server components work fine, but you can't use Node.js APIs like 'fs' at runtime. OpenNext handles the adaptation automatically.",{"q":224,"a":225},"What happens when I exceed 100K requests/day?","Cloudflare charges $0.50 per million requests after that. For a portfolio, you'd need viral traffic to hit this. I've never exceeded it.",{"q":227,"a":228},"Do I need to change my Next.js code significantly?","Minimal changes. Main constraint is no filesystem access at runtime. Use prebuild scripts to generate JSON from MDX/markdown instead of reading files dynamically.",{"q":230,"a":231},"How does performance compare to Vercel?","Equal or better. Both use edge networks, but Cloudflare's V8 isolates have faster cold starts than Vercel's serverless functions. Real-world: 20-50ms response times globally.",{"name":233,"totalTime":234,"steps":235},"How to Deploy Next.js to Cloudflare Workers","PT20M",[236,239,242,245],{"name":237,"text":238},"Install OpenNext Cloudflare adapter","Run 'bun add -D @opennextjs/cloudflare' and create wrangler.jsonc config file with worker name and compatibility flags.",{"name":240,"text":241},"Add build scripts to package.json","Add 'preview' script for local testing and 'deploy' script that runs Next.js build followed by OpenNext build and Cloudflare deployment.",{"name":243,"text":244},"Configure edge-compatible code","Replace any Node.js filesystem calls with prebuild scripts. Generate static JSON files at build time instead of reading dynamically at runtime.",{"name":246,"text":247},"Deploy to Cloudflare","Run 'bun run deploy' to build and upload. Your site will be live on workers.dev subdomain immediately, then add custom domain in Cloudflare dashboard.","I haven't paid for hosting in two years. Not because I'm using some sketchy free trial, but because my portfolio genuinely costs $0/month to run on Cloudflare Workers.\n\nThis isn't a flex post. It's the architecture breakdown of how divkix.me runs on Cloudflare's edge network with Next.js 15, why I picked it over Vercel, and the actual constraints you'll hit.\n\n## The Stack Nobody Tells You About\n\nHere's what powers this site:\n\n- **Next.js 15** (App Router, RSC)\n- **OpenNext** (`@opennextjs/cloudflare`) - the adapter that makes Next.js work on Workers\n- **Cloudflare Workers** - edge runtime using V8 isolates\n- **Wrangler** - Cloudflare's deployment CLI\n\nThe secret sauce is OpenNext. It's an open-source adapter that converts Next.js builds into formats that edge runtimes understand. You can't just deploy Next.js to Cloudflare Workers directly. OpenNext bridges the gap.\n\n## Why Not Vercel? (The Real Reasons)\n\nVercel hosts Next.js perfectly. But here's why I left:\n\n**1. Free Tier Limits**\n\nVercel's free tier gives you 100GB bandwidth. That sounds like a lot until you add images, videos, or get a Reddit hug of death. Cloudflare? Unlimited bandwidth. Period.\n\n**2. Vendor Lock-In**\n\nVercel owns Next.js. Great for integration, terrible for negotiating power. If they change pricing or terms, you're stuck migrating. Cloudflare Workers runs on open web standards.\n\n**3. Cold Starts**\n\nVercel's serverless functions use containers. Cold starts are 200-500ms. Cloudflare Workers use V8 isolates - basically lightweight JS contexts. Cold starts? 5ms. Not 5 seconds. 5 milliseconds.\n\n**4. Global Edge = Default**\n\nVercel Edge Functions cost extra. Cloudflare Workers deploy to 330+ cities automatically. No configuration. No upcharge.\n\n## The Free Tier Reality Check\n\nLet's compare the actual numbers:\n\n| Feature | Cloudflare Workers | Vercel | Netlify |\n|---------|-------------------|--------|---------|\n| Requests/Day | 100,000 | Unlimited* | Unlimited* |\n| Bandwidth | Unlimited | 100GB | 100GB |\n| Function Invocations | 100K/day | 100 hours compute | 125K/month |\n| Cold Start Time | ~5ms | 200-500ms | 200-500ms |\n| Global Edge | Yes (330+ cities) | $20/mo add-on | Paid plans only |\n| Overage Cost | $0.50/1M requests | Pay-as-you-go | Pay-as-you-go |\n\n*Vercel/Netlify limit bandwidth, not requests. Hit 100GB and you're throttled or billed.\n\nFor a portfolio or blog, you'll never hit 100K requests/day unless you're Hacker News frontpage famous. I average 2-3K requests/day. Not even close.\n\n## Edge Runtime Constraints (The Pain Points)\n\nCloudflare Workers run on the edge. That means no Node.js. No filesystem. No `fs.readFileSync()`. This breaks a lot of Next.js patterns.\n\n### The Blog Problem\n\nMy blog uses MDX files. Typical Next.js pattern:\n\n```typescript\n// This DOES NOT WORK on Cloudflare Workers\nimport fs from 'fs';\nimport path from 'path';\n\nexport function getBlogPosts() {\n  const files = fs.readdirSync('content/blog');\n  return files.map(file => {\n    const content = fs.readFileSync(`content/blog/${file}`);\n    return parseMDX(content);\n  });\n}\n```\n\nNo `fs` module at runtime. The solution? **Prebuild everything.**\n\n### The Prebuild Pattern\n\nI wrote a build script that runs before deployment:\n\n```javascript\n// scripts/generate-posts-metadata.js\nimport fs from 'fs';\nimport path from 'path';\nimport matter from 'gray-matter';\n\nconst postsDir = 'content/blog';\nconst files = fs.readdirSync(postsDir).filter(f => f.endsWith('.mdx'));\n\nconst posts = files.map(filename => {\n  const content = fs.readFileSync(path.join(postsDir, filename), 'utf8');\n  const { data } = matter(content);\n  return {\n    slug: filename.replace('.mdx', ''),\n    ...data,\n    readingTime: calculateReadingTime(content)\n  };\n});\n\nfs.writeFileSync('content/blog/posts.json', JSON.stringify(posts, null, 2));\n```\n\nNow at runtime, I just import the JSON:\n\n```typescript\n// lib/content.ts\nimport postsData from '@/content/blog/posts.json';\n\nexport function getAllPosts() {\n  return postsData; // No filesystem needed\n}\n```\n\nThis runs at build time with Node.js, outputs static JSON, and the edge runtime only reads JSON. Problem solved.\n\n## Wrangler Config Basics\n\nHere's the minimal `wrangler.jsonc` config:\n\n```json\n{\n  \"name\": \"divkix-me\",\n  \"compatibility_date\": \"2025-11-24\",\n  \"compatibility_flags\": [\n    \"nodejs_compat\",\n    \"global_fetch_strictly_public\"\n  ],\n  \"assets\": {\n    \"directory\": \".open-next/assets\"\n  }\n}\n```\n\n- `nodejs_compat` enables some Node.js APIs (Buffer, process.env)\n- `global_fetch_strictly_public` enforces standards-compliant fetch\n- `assets.directory` points to OpenNext's build output\n\nOpenNext generates `.open-next/` folder with all Worker-compatible assets. Wrangler uploads it.\n\n## Performance: The Actual Numbers\n\nI ran tests from 5 global locations. Here's reality:\n\n**Homepage (SSG)**\n- San Francisco: 23ms\n- London: 31ms\n- Singapore: 28ms\n- Mumbai: 35ms\n- São Paulo: 42ms\n\n**Blog Post (SSR)**\n- San Francisco: 45ms\n- London: 52ms\n- Singapore: 48ms\n- Mumbai: 61ms\n- São Paulo: 58ms\n\nThese are total response times, not TTFB. Cold starts are invisible. V8 isolates are fast.\n\nFor comparison, my old Vercel setup averaged 80-120ms on dynamic routes because of container cold starts.\n\n## Build and Deploy Commands\n\nMy `package.json` scripts:\n\n```json\n{\n  \"scripts\": {\n    \"prebuild\": \"node scripts/generate-posts-metadata.js\",\n    \"build\": \"bun run prebuild && next build\",\n    \"preview\": \"bun run build && wrangler pages dev .open-next/assets\",\n    \"deploy\": \"bun run build && wrangler pages deploy .open-next/assets\"\n  }\n}\n```\n\nWorkflow:\n1. `bun run prebuild` - generates posts.json from MDX\n2. `next build` - Next.js builds app\n3. OpenNext transforms output (happens automatically via next.config)\n4. `wrangler pages deploy` - uploads to Cloudflare\n\nFirst deploy took 2 minutes. Updates take 30-45 seconds.\n\n## The Honest Downsides\n\n**1. Debugging Is Harder**\n\nLocal development uses Node.js. Production uses V8 isolates. Sometimes code works locally but breaks on Workers. You'll need to test with `wrangler pages dev` before deploying.\n\n**2. No Incremental Static Regeneration (ISR)**\n\nNext.js ISR doesn't work on Workers. You get static or fully dynamic. No middle ground. For a portfolio, this doesn't matter. For a high-traffic blog, you'll need full SSR or static builds.\n\n**3. OpenNext Is Community-Maintained**\n\nVercel isn't maintaining this. The community is. Updates lag behind Next.js releases. I'm on Next.js 15.0, OpenNext adapter works, but edge cases exist.\n\n**4. Limited Node.js APIs**\n\n`nodejs_compat` flag enables some APIs, but not everything. No child processes, no native modules, no complex crypto. Check compatibility before committing.\n\n**5. Build Times**\n\nOpenNext adds 10-15 seconds to build time. Not terrible, but noticeable. Vercel builds are faster because they control the entire stack.\n\n## When You'd Actually Pay\n\nCloudflare charges after 100K requests/day. Let's math this out:\n\n- 100K requests/day = 3M requests/month (free)\n- Next 10M requests = $5\n- 13M requests/month = $5 total\n\nCompare to Vercel Hobby (free) → Pro ($20/mo) jump. No middle ground.\n\nFor context, a site getting 13M requests/month is doing 430K requests/day. That's 180 requests/minute every minute of every day. Your portfolio won't hit this unless it's not a portfolio anymore.\n\n## The Migration Path\n\nIf you're on Vercel now:\n\n1. Install OpenNext: `bun add -D @opennextjs/cloudflare`\n2. Create `wrangler.jsonc` with basic config\n3. Audit your code for `fs`, `path`, Node.js APIs\n4. Move filesystem operations to prebuild scripts\n5. Test locally: `bun run preview`\n6. Deploy: `bun run deploy`\n7. Add custom domain in Cloudflare dashboard\n\nI migrated in 3 hours. Most of that was rewriting the blog system to use prebuild JSON instead of runtime filesystem reads.\n\n## Should You Do This?\n\n**Yes, if:**\n- You want $0/month hosting with no asterisks\n- You're building a portfolio, blog, or low-traffic site\n- You're comfortable with edge runtime constraints\n- You value fast cold starts and global edge\n\n**No, if:**\n- You need ISR (revalidate every X seconds)\n- You rely heavily on Node.js-specific libraries\n- You want zero-config deployment (Vercel is easier)\n- Your site uses database connections extensively (Workers have connection limits)\n\nFor divkix.me, Cloudflare Workers is perfect. No hosting bills, global performance, and the constraints force better architecture decisions. I prebuild everything anyway. Why not make it official?\n\nThe free tier isn't a trial. It's permanent. Cloudflare makes money from enterprises, not personal portfolios. Use that to your advantage.\n\n---\n\n**Resources:**\n- [OpenNext Documentation](https://opennext.js.org)\n- [Cloudflare Workers Docs](https://developers.cloudflare.com/workers)\n- [My Portfolio Source Code](https://github.com/divkix/divkix.me) (see wrangler.jsonc and prebuild scripts)\n\nThe hosting bill that doesn't exist? That's not a hack. That's just picking the right tool for the job.","src/content/blog/zero-cost-portfolio-cloudflare-workers.mdx","dec514016d8daa69","zero-cost-portfolio-cloudflare-workers.mdx","side-project-stack-2025-grad-student",{"id":252,"data":254,"body":284,"filePath":285,"digest":286,"legacyId":287,"deferredRender":31},{"title":255,"date":15,"excerpt":256,"tags":257,"published":31,"author":32,"tldr":264,"keyTakeaways":265,"faq":271},"My 2025 Stack for Shipping Side Projects Fast as a Grad Student","How I shipped 30+ projects while getting my MS in Computer Science at ASU. The stack choices that let me build fast, deploy faster, and actually sleep at night. Real lessons from PickMyClass, Alita Robot, and projects serving 250K+ users.",[258,259,260,67,69,261,262,263,27,28],"Side Projects","Tech Stack","Grad Student","Cloudflare","TypeScript","Building in Public","Time-starved grad student's battle-tested stack: Next.js 15 + TypeScript + Supabase + Cloudflare Workers. Optimized for shipping fast, not resume padding.",[266,267,268,269,270],"Use managed services (Supabase, Cloudflare) to eliminate ops work - your time is more valuable than $5/month","TypeScript is non-negotiable for side projects you'll touch 6 months later","Copy-paste UI components (shadcn/ui) beats building from scratch every time","Deployment should be boring - Cloudflare Workers deploy in 30 seconds and cost $0","Optimize for iteration speed over architectural purity when shipping under time pressure",[272,275,278,281],{"q":273,"a":274},"Why not just use Python/Django for everything?","I tried. TypeScript catches so many bugs before deployment that I stopped fighting it. Plus Next.js gives you SSR, API routes, and deployment in one package.",{"q":276,"a":277},"Isn't Supabase vendor lock-in?","Yes, and I don't care. For side projects, the alternative is spending weekends debugging Postgres connections. Supabase's free tier is ridiculously generous and I can always migrate if a project actually makes money.",{"q":279,"a":280},"What about costs at scale?","PickMyClass serves thousands of students on Cloudflare's free tier. Alita Robot (1M+ users) runs on minimal infra. Most projects never hit paid tiers. If they do, you've got bigger problems to solve (good problems).",{"q":282,"a":283},"Why Biome over ESLint + Prettier?","20x faster, one config file, zero conflicts between linter and formatter. Migrated all my projects in 2024 and never looked back. Time saved adds up.","I've shipped 30+ projects while getting my master's degree in Computer Science at ASU. None of them are perfect. Most serve specific needs. A few have actually scaled to real users—PickMyClass helps thousands of ASU students grab classes, Alita Robot serves over 1 million Telegram users.\n\nHere's the thing nobody tells you about side projects in grad school: you don't have time. Between CS courses, TA work, and pretending to have a social life, every tech decision is a time trade-off. Pick the wrong stack and you'll spend weekends debugging CORS errors instead of shipping features.\n\nThis is the stack I landed on after burning time on frameworks that promised \"developer experience\" but delivered dependency hell.\n\n## The Constraint: Time is the Enemy\n\nI have maybe 10-15 hours a week for side projects. That's it. Every hour spent on setup, configuration, or deployment is an hour not spent building the actual thing people will use.\n\nThis constraint shaped everything. I don't pick technologies because they look good on a resume. I pick them because they let me ship fast and move on to the next idea.\n\nMost side projects fail not because the idea was bad, but because you gave up before shipping. The stack's job is to get out of your way.\n\n## The Core Stack\n\n### Next.js 15 (App Router)\n\nYeah, I know. \"Another Next.js fanboy.\" Hear me out.\n\nI've built projects in Flask, Django, FastAPI, SvelteKit, and vanilla React. Next.js won because it handles SSR, API routes, routing, and deployment configuration in one framework. No webpack configs. No separate backend server. No arguing with yourself about project structure at 2 AM.\n\nThe App Router (Next.js 13+) finally makes server components feel natural. I can fetch data directly in components without prop drilling or useState soup. For a student project that needs to work in 2 weeks, this matters.\n\n**Why not Astro/Remix/SvelteKit?** Astro is great for content sites but limiting for interactive apps. Remix is solid but smaller ecosystem. SvelteKit is lovely but I'm already productive in React and don't have time to context-switch. Next.js isn't perfect but it's predictable.\n\n### TypeScript - Non-Negotiable\n\nI used to write JavaScript and tell myself \"I'll add types later.\" Later never came. I'd revisit code after 3 months and have zero idea what shape the data was supposed to be.\n\nTypeScript catches bugs before they hit production. When you're juggling coursework and projects, you can't afford silent runtime errors that only surface when users complain.\n\nThe autocomplete alone saves hours. No more cmd+tabbing to docs to remember function signatures.\n\n### Supabase - Database + Auth + Realtime\n\nThis is where I save the most time. Supabase gives you Postgres, authentication, real-time subscriptions, storage, and Edge Functions in one platform.\n\n**PickMyClass example:** I needed to monitor ASU class availability and notify students instantly. With Supabase, I set up database triggers that fire Edge Functions when class seats open up. No Redis, no message queues, no Docker Compose files. Just SQL and TypeScript.\n\nI optimized one query from 40 seconds to 16 milliseconds—a 2,500x speedup—by adding proper indexes. Supabase's dashboard made this trivial. You can see slow queries, explain plans, and add indexes without SSHing into servers.\n\nThe free tier is absurdly generous: 500 MB database, 50k monthly active users, 2GB file storage. Most student projects never leave free tier.\n\n**Why not Firebase?** I tried. Firestore's NoSQL model is great until you need to query data in ways you didn't plan for. Postgres lets me change my mind. Also, vendor lock-in with Firebase's proprietary query language scared me more than Supabase (which is just Postgres).\n\n### Cloudflare Workers - Deploy and Forget\n\nI deploy to Cloudflare Workers using OpenNext. Here's the entire deployment process:\n\n```bash\nbun run deploy\n```\n\nThat's it. No EC2 instances. No Nginx configs. No PM2 processes dying at 3 AM. Workers boot in milliseconds, scale automatically, and cost $0 for most projects.\n\nMy portfolio site (the one you're reading this on) serves global traffic on Cloudflare's free tier. Zero cold starts. Zero downtime in 6 months.\n\n**The catch:** No filesystem access at runtime. You can't read files dynamically. Everything needs to be bundled at build time. For my blog, I pre-generate metadata from MDX files into JSON. Annoying initially, but forces you to think about edge compatibility.\n\n## The Speed Tools\n\n### shadcn/ui - Copy-Paste Components\n\nI wasted so much time building modals, dropdowns, and form inputs from scratch. shadcn/ui changed this.\n\nIt's not a component library you install. You copy the component code into your project. Built on Radix UI primitives (accessible) and styled with Tailwind. If you need to customize, you just edit the code. No fighting with CSS overrides or `!important` hacks.\n\nI can scaffold a full dashboard UI in 30 minutes. Forms with validation, data tables, modals, toasts—all copy-paste. This is the cheat code.\n\n### Tailwind CSS - No Context Switching\n\nUtility classes are ugly until you realize you never leave your HTML file to write CSS. No naming things. No cascading bugs. No wondering which stylesheet is overriding your button color.\n\nI use Tailwind v4 now (still in alpha but stable enough). The new CSS variable system is cleaner. My entire color palette lives in `globals.css` and supports dark mode automatically.\n\n**Hot take:** If you're building alone and moving fast, semantic CSS is a waste of time. Tailwind's verbosity is a feature, not a bug. You can read a component and know exactly what it looks like without opening DevTools.\n\n### Biome - Fast Linting/Formatting\n\nIn 2024 I ripped out ESLint and Prettier from all my projects and replaced them with Biome. Single tool, zero conflicts, 20x faster.\n\nESLint + Prettier always fought over formatting rules. Biome handles both in one config file. Runs linting and formatting in parallel. Saves 3-5 seconds on every commit hook, which adds up to hours over a semester.\n\n## Real Project Examples\n\n### PickMyClass: Supabase Scaling\n\nPickMyClass monitors ASU course enrollment and texts students when seats open. Built in a weekend, now used by thousands of students every semester.\n\n**The scaling problem:** Initially, I was fetching all class data on every request. 40-second load times. Terrible UX.\n\n**The fix:** Added Postgres indexes on course number and semester columns. Load time dropped to 16ms. That's 2,500x faster. I didn't change databases or add caching layers. Just proper indexing.\n\nSupabase's query analyzer showed me exactly which queries were slow. Fixed in an afternoon. This is why I use Postgres over NoSQL—you can optimize when you need to without rewriting everything.\n\n### Alita Robot: Go for High Traffic\n\nAlita is a Telegram bot serving 1M+ users. I wrote it in Go, not TypeScript.\n\n**Why Go here?** Telegram bots need to handle webhooks fast. Go's concurrency model (goroutines) makes this trivial. The bot handles thousands of concurrent requests without breaking a sweat.\n\nI use TypeScript for web apps and Go for high-throughput services. Don't be dogmatic about one language. Use the right tool.\n\nThe bot runs on minimal infrastructure—single VPS, no load balancer. Go's performance headroom is insane compared to Node.js for this use case.\n\n## Lessons from 250K+ Users\n\n**Lesson 1: Managed services beat custom infrastructure every time.**\n\nI used to self-host Postgres in Docker. Spent more time on backups, updates, and \"why is this container restarting\" than building features. Supabase costs $0 for most projects and handles all of that.\n\nYour time is worth more than $10/month. If you're optimizing cloud costs before you have users, you're optimizing the wrong thing.\n\n**Lesson 2: TypeScript saves you from yourself.**\n\nHalf the bugs I catch are type errors that would've been runtime crashes. When users depend on your project (like students trying to enroll in classes), silent failures aren't acceptable.\n\n**Lesson 3: Deployment friction kills projects.**\n\nIf deploying takes more than 5 minutes, you'll do it less often. Smaller, frequent deploys mean fewer bugs. Cloudflare Workers and Vercel make deployment boring, which is exactly what you want.\n\n**Lesson 4: Users don't care about your stack.**\n\nPickMyClass users care that they get notified when CS 101 has seats. They don't care if it's built in Next.js or Ruby on Rails. Ship fast, iterate based on feedback, move on.\n\n## The Stack Decisions I Regret\n\n**Using MongoDB for early projects.** I thought schemaless was \"flexible.\" It was chaos. Every query was a gamble. Migrating to Postgres (via Supabase) fixed this. Schemas are good actually.\n\n**Not using TypeScript from day one.** I have 5 projects in plain JavaScript that I'm scared to touch now. Adding types retroactively is painful. Just start with TypeScript.\n\n**Over-engineering before users.** I built elaborate caching layers and microservices before anyone used the product. Wasted weeks. Start with a monolith. Scale when you need to (you probably won't).\n\n**Avoiding vendor lock-in too hard.** I spent days setting up self-hosted auth instead of using Supabase Auth. The self-hosted version broke three times. Supabase Auth has worked flawlessly for 2 years. Pragmatism beats purity.\n\n## What I'd Tell Past Me\n\nStart with this stack. Don't experiment with \"interesting\" tech until you've shipped 5 projects with boring tech.\n\nCopy more code. Every form validation schema you write from scratch is time you didn't spend on the unique part of your idea.\n\nUse managed services aggressively. Database, auth, file storage, email—all solvable with Supabase, Cloudflare, and Resend. Don't self-host unless you're learning DevOps specifically.\n\nShip incomplete projects. PickMyClass launched with zero tests and one feature. Users gave feedback. I iterated. Perfect is the enemy of shipped.\n\nTypeScript, linting, and formatting are non-negotiable. Future you will thank present you.\n\n## Quick Stack Comparison\n\n**This stack vs MERN (Mongo, Express, React, Node):**\n- Next.js handles routing + API routes (no Express needed)\n- Postgres > Mongo for relational data (most data is relational)\n- TypeScript catches bugs Mongo's schemaless design hides\n\n**This stack vs Django + React:**\n- Django is great but overkill for side projects\n- Next.js unifies frontend/backend (no CORS, no separate deploys)\n- Python is slower than Node for I/O-heavy tasks\n\n**This stack vs Serverless Framework:**\n- Next.js on Cloudflare Workers IS serverless\n- Less configuration, better DX\n- OpenNext handles the messy parts\n\n**This stack vs Rails:**\n- Rails is incredible for rapid prototyping but heavier\n- I already know TypeScript well (leverage existing skills)\n- Next.js ecosystem moves faster\n\n## The Bottom Line\n\nThis stack lets me go from idea to deployed project in a weekend. That's the metric that matters when you're a grad student with 10 hours a week.\n\nNext.js for frontend + API routes. TypeScript for sanity. Supabase for database + auth. Cloudflare Workers for deployment. shadcn/ui for UI. Tailwind for styling. Biome for linting/formatting.\n\nNone of these are the \"best\" tools in isolation. Together, they minimize the time between idea and shipped product. That's what matters.\n\nYour mileage will vary. If you're deep in the Python ecosystem, FastAPI + Postgres + Vercel might be better. If you're building mobile apps, React Native + Supabase makes sense. The principle is the same: pick tools that let you ship fast and stay out of your way.\n\nI've got 6 more project ideas and 5 months until graduation. This stack will ship them all. Or I'll learn something new and write another post about what I got wrong.\n\nNow stop reading and go build something.","src/content/blog/side-project-stack-2025-grad-student.mdx","0e8081df8c9795b1","side-project-stack-2025-grad-student.mdx"]